# DocuQuery - RAG System

A production-ready **Retrieval-Augmented Generation (RAG)** system that enables users to upload documents and query them using natural language. Built with Python, LangChain, FAISS, Flask, and OpenAI GPT-4.

## Features

- üìÑ **Multi-format Document Support**: Upload PDF, DOCX, and TXT files
- üîç **Semantic Search**: FAISS-powered vector similarity search
- ü§ñ **AI-Powered Answers**: Context-aware responses using GPT-4
- üíæ **Metadata Storage**: MongoDB for document tracking
- üöÄ **REST API**: Clean endpoints for integration
- ‚ö° **Optimized Performance**: Response latency < 2 seconds

## Architecture

```
User ‚Üí Flask API ‚Üí Document Processor ‚Üí Text Chunker ‚Üí OpenAI Embeddings ‚Üí FAISS Vector Store
                ‚Üì                                                                    ‚Üì
            MongoDB (Metadata)                                              Similarity Search
                                                                                    ‚Üì
                                                                            GPT-4 LLM ‚Üí Answer
```

## Installation

### Prerequisites

- Python 3.8+
- MongoDB (local or cloud)
- OpenAI API key

### Setup

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd pythonProject
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment**
   ```bash
   cp .env.example .env
   ```
   
   Edit `.env` and add your credentials:
   ```env
   OPENAI_API_KEY=sk-your-openai-api-key
   MONGODB_URI=mongodb://localhost:27017/docuquery
   ```

5. **Start MongoDB** (if running locally)
   ```bash
   mongod
   ```

## Usage

### Start the Server

```bash
python app.py
```

The server will start on `http://localhost:5000`

### API Endpoints

#### 1. Health Check
```bash
GET /api/health
```

**Response:**
```json
{
  "status": "healthy",
  "vector_store_size": 150,
  "document_count": 5
}
```

#### 2. Upload Document
```bash
POST /api/upload
Content-Type: multipart/form-data

file: <your-document.pdf>
```

**Response:**
```json
{
  "document_id": "uuid-here",
  "filename": "document.pdf",
  "chunk_count": 25,
  "status": "processed",
  "message": "Document uploaded and processed successfully"
}
```

#### 3. Query Documents
```bash
POST /api/query
Content-Type: application/json

{
  "query": "What is the main topic of the document?",
  "top_k": 3
}
```

**Response:**
```json
{
  "query": "What is the main topic of the document?",
  "answer": "Based on the provided documents, the main topic is...",
  "sources": [
    {
      "filename": "document.pdf",
      "chunk_index": 5,
      "text_preview": "...",
      "similarity_score": 0.85
    }
  ],
  "confidence": 0.9,
  "chunks_retrieved": 3
}
```

#### 4. List Documents
```bash
GET /api/documents
```

**Response:**
```json
{
  "documents": [
    {
      "document_id": "uuid-here",
      "filename": "document.pdf",
      "chunk_count": 25,
      "upload_time": "2025-12-18T05:30:00Z",
      "status": "processed"
    }
  ],
  "count": 1
}
```

#### 5. Delete Document
```bash
DELETE /api/documents/<document_id>
```

**Response:**
```json
{
  "message": "Document deleted successfully",
  "document_id": "uuid-here",
  "note": "Vector embeddings persist in FAISS index"
}
```

## Project Structure

```
pythonProject/
‚îú‚îÄ‚îÄ app.py                      # Main Flask application
‚îú‚îÄ‚îÄ config.py                   # Configuration management
‚îú‚îÄ‚îÄ requirements.txt            # Python dependencies
‚îú‚îÄ‚îÄ .env.example               # Environment template
‚îú‚îÄ‚îÄ .gitignore                 # Git ignore rules
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ document_processor.py  # Document text extraction
‚îÇ   ‚îú‚îÄ‚îÄ text_chunker.py        # Text chunking logic
‚îÇ   ‚îú‚îÄ‚îÄ vector_store.py        # FAISS vector operations
‚îÇ   ‚îî‚îÄ‚îÄ llm_handler.py         # LLM integration
‚îú‚îÄ‚îÄ database/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ mongodb_handler.py     # MongoDB operations
‚îú‚îÄ‚îÄ uploads/                   # Uploaded documents (auto-created)
‚îî‚îÄ‚îÄ vector_store/              # FAISS indices (auto-created)
```

## Configuration

Key configuration options in `.env`:

| Variable | Description | Default |
|----------|-------------|---------|
| `OPENAI_API_KEY` | OpenAI API key | Required |
| `MONGODB_URI` | MongoDB connection string | `mongodb://localhost:27017/docuquery` |
| `CHUNK_SIZE` | Text chunk size | 1000 |
| `CHUNK_OVERLAP` | Overlap between chunks | 200 |
| `TOP_K_RESULTS` | Number of results to retrieve | 3 |
| `LLM_TEMPERATURE` | LLM creativity (0-1) | 0.7 |

## Testing

### Using cURL

**Upload a document:**
```bash
curl -X POST -F "file=@sample.pdf" http://localhost:5000/api/upload
```

**Query the system:**
```bash
curl -X POST -H "Content-Type: application/json" \
  -d '{"query": "What is this document about?"}' \
  http://localhost:5000/api/query
```

### Using Python

```python
import requests

# Upload document
with open('sample.pdf', 'rb') as f:
    response = requests.post('http://localhost:5000/api/upload', files={'file': f})
    print(response.json())

# Query
response = requests.post('http://localhost:5000/api/query', 
    json={'query': 'What is the main topic?'})
print(response.json())
```

## Technologies

- **Flask**: Web framework
- **LangChain**: RAG orchestration
- **FAISS**: Vector similarity search
- **OpenAI**: Embeddings (text-embedding-3-small) & LLM (GPT-4)
- **MongoDB**: Document metadata storage
- **PyPDF2**: PDF processing
- **python-docx**: Word document processing

## Performance Optimization

- **Vector Store Persistence**: FAISS index saved to disk
- **Connection Pooling**: MongoDB connection reuse
- **Efficient Chunking**: Optimized chunk size for context/speed balance
- **Caching**: Embedding caching for repeated queries

## Limitations

- Maximum file size: 16MB
- Supported formats: PDF, DOCX, TXT
- Vector store deletion requires manual rebuild
- Requires active internet connection for OpenAI API

## Troubleshooting

**MongoDB Connection Error:**
```bash
# Ensure MongoDB is running
mongod --dbpath /path/to/data
```

**OpenAI API Error:**
- Verify API key in `.env`
- Check API quota and billing

**Import Errors:**
```bash
pip install -r requirements.txt --upgrade
```

## License

MIT License

## Contributing

Contributions welcome! Please open an issue or submit a pull request.

## Author

Built with ‚ù§Ô∏è using Python, LangChain, and OpenAI
